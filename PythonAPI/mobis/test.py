#!/usr/bin/env python

# Copyright (c) 2017 Computer Vision Center (CVC) at the Universitat Autonoma de
# Barcelona (UAB).
#
# This work is licensed under the terms of the MIT license.
# For a copy, see <https://opensource.org/licenses/MIT>.

import glob
import os
import sys
import math
import numpy as np
import pickle
import datetime
from numpy.matlib import repmat

try:
    import pygame
except ImportError:
    raise RuntimeError('cannot import pygame, make sure pygame package is installed')

try:
    sys.path.append(glob.glob('**/*%d.%d-%s.egg' % (
        sys.version_info.major,
        sys.version_info.minor,
        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])
except IndexError:
    pass

import carla
import random
import time
import cv2

from PIL import Image, ImageDraw
import PIL.ImageOps

actor_list = []


def saveimage(path, image, converter):
    filepath = os.path.join(path, '%06d.tiff' % image.frame_number)
    # saveimageobj(image, filepath)
    image.save_to_disk(filepath, converter)

def saveimage_id(path, image, converter, id):
    filepath = os.path.join(path, '{}_{}.tiff'.format(image.frame_number, id))
    # saveimageobj(image, filepath)
    image.save_to_disk(filepath, converter)


def saveimageobj(data, filename):
    with open(filename + '.pkl', 'wb') as output:
        pickle.dump(data, output)


def getcurtimestr():
    currentDT = datetime.datetime.now()
    return (currentDT.strftime("%Y%m%d_%H%M%S"))


def main():
    foldername = os.path.join('./_out', getcurtimestr())
    pygame.init()

    # In this tutorial script, we are going to add a vehicle to the simulation
    # and let it drive in autopilot. We will also create a camera attached to
    # that vehicle, and save all the images generated by the camera to disk.

    try:
        # First of all, we need to create the client that will send the requests
        # to the simulator. Here we'll assume the simulator is accepting
        # requests in the localhost at port 2000.
        client = carla.Client('localhost', 2000)
        client.set_timeout(2.0)

        # Once we have a client we can retrieve the world that is currently
        # running.
        world = client.get_world()

        # The world contains the list blueprints that we can use for adding new
        # actors into the simulation.
        blueprint_library = world.get_blueprint_library()

        # Now let's filter all the blueprints of type 'vehicle' and choose one
        # at random.
        bp_vehicle = random.choice(blueprint_library.filter('vehicle.toyota.*'))
        bp_bike = random.choice(blueprint_library.filter('crossbike'))

        transform1 = carla.Transform(carla.Location(x=-74.6, y=148.7, z=5), carla.Rotation(yaw=-90))
        transform2 = carla.Transform(carla.Location(x=-74.8, y=158.5, z=5), carla.Rotation(yaw=-90))
        transform3 = carla.Transform(carla.Location(x=-77.9, y=148.4, z=5), carla.Rotation(yaw=-90))
        transform4 = carla.Transform(carla.Location(x=-77.7, y=154.7, z=5), carla.Rotation(yaw=-90))
        transform5 = carla.Transform(carla.Location(x=-76.3, y=141.7, z=5))

        def addvehicle(bp, transform):
            color = random.choice(bp.get_attribute('color').recommended_values)
            bp.set_attribute('color', color)
            vehicle = world.spawn_actor(bp, transform)
            actor_list.append(vehicle)
            print('created %s' % vehicle.type_id)
            return vehicle

        vehicle1 = addvehicle(bp_vehicle, transform1)
        vehicle2 = addvehicle(bp_vehicle, transform2)
        vehicle3 = addvehicle(bp_vehicle, transform3)
        vehicle4 = addvehicle(bp_vehicle, transform4)
        bike1 = addvehicle(bp_bike, transform5)

        # Let's put the vehicle to drive around.
        vehicle1.set_autopilot(True)
        vehicle2.set_autopilot(True)
        vehicle3.set_autopilot(True)
        vehicle4.set_autopilot(True)
        bike1.set_autopilot(True)

        def addsensor(bp, transform, vehicle):
            sensor = world.spawn_actor(bp, transform, attach_to=vehicle)
            actor_list.append(sensor)
            print('created %s' % sensor.type_id)
            return sensor

        def addsensors(vehicle, sensorslist=[0], sensor_transform=None):
            # sensorlist: 0 is rgb, 1 is depth, 2 is semantic_segmentation
            if sensor_transform is None:
                sensor_transform = carla.Transform(carla.Location(x=1, z=1.5))
            for sensor in sensorslist:
                if sensor == 0:
                    camera_rgb_bp = blueprint_library.find('sensor.camera.rgb')
                    camera_rgb = addsensor(camera_rgb_bp, sensor_transform, vehicle)
                    path1 = os.path.join(foldername, 'rgb'+ str(camera_rgb.id))
                    if not os.path.exists(path1): os.makedirs(path1)
                    cc_raw = carla.ColorConverter.Raw
                    #time.sleep(1)
                    camera_rgb.listen(lambda image: saveimage_id(path1, image, cc_raw, camera_rgb.id))
                elif sensor == 1:
                    camera_depth_bp = blueprint_library.find('sensor.camera.depth')
                    camera_depth = addsensor(camera_depth_bp, sensor_transform, vehicle)
                    path2 = os.path.join(foldername, 'depth')
                    if not os.path.exists(path2): os.makedirs(path2)
                    cc_depth = carla.ColorConverter.LogarithmicDepth
                    #time.sleep(1)
                    # camera_depth.listen(lambda image: saveimage(path2, image, cc_depth))
                    camera_depth.listen(lambda image: saveimage_id(path2, image, cc_depth, camera_depth.id))
                elif sensor == 2:
                    camera_seg_bp = blueprint_library.find('sensor.camera.semantic_segmentation')
                    camera_seg = addsensor(camera_seg_bp, sensor_transform, vehicle)
                    path3 = os.path.join(foldername, 'seg')
                    if not os.path.exists(path3): os.makedirs(path3)
                    cc_seg = carla.ColorConverter.CityScapesPalette
                    time.sleep(1)
                    # camera_seg.listen(lambda image: saveimage(path3, image, cc_seg))
                    camera_seg.listen(lambda image: saveimage_id(path3, image, cc_seg, camera_seg.id))

        time.sleep(2)
        print("before adding sensors")

        addsensors(vehicle1, sensorslist=[1])
        addsensors(vehicle2)
        addsensors(vehicle3, sensorslist=[2])
        addsensors(vehicle4)

        a = 10
        print("after adding sensors")

        time.sleep(2)

    finally:

        print('destroying actors')
        for actor in actor_list:
            actor.destroy()
        print('done.')


def test_blend():
    path = '/home/mobis/CARLA2/carla/PythonAPI/mobis/_out/20190423_143318/'
    rgb_folder = os.path.join(path, 'rgb/')
    instance_folder = os.path.join(path, 'instance/')
    bb_folder = os.path.join(path, '2dbb/')
    mod_folder = os.path.join(path, 'mod/')
    output_fodler = os.path.join(path, 'combined/')
    if not os.path.exists(output_fodler): os.makedirs(output_fodler)

    path, dirs, files = next(os.walk(rgb_folder))
    num_zeros = len(files[0].split('.')[0])

    indices = [int(file.split('.')[0]) for file in files]

    indices.sort()

    imnames = [str(value).zfill(num_zeros)+'.png' for value in indices]

    for name in imnames:
        img21 = cv2.imread('/home/mobis/CARLA2/carla/PythonAPI/mobis/_out/20190423_143318/instance/00000101.png')
        img1 = cv2.imread(os.path.join(rgb_folder, name))
        img2 = cv2.imread(os.path.join(instance_folder, name))
        img3 = cv2.imread(os.path.join(mod_folder, name))
        img4 = cv2.imread(os.path.join(bb_folder, name))

        h1, w1 = img1.shape[:2]
        vis = np.zeros((h1*2, w1*2, 3), np.uint8)
        vis[0:h1, 0:w1, :] = img1
        vis[h1:2*h1, :w1,:] = img3
        vis[:h1, w1:2*w1,:] = img2
        vis[h1:2*h1, w1:2*w1,:] = img4

        final_output_fodler = os.path.join(output_fodler, name)

        cv2.imwrite(final_output_fodler, vis)


if __name__ == '__main__':
    # main()
    test_blend()